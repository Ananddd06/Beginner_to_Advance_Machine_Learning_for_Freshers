# Bootstrap Explained with Code

## Overview

The **Bootstrap** is a resampling method that allows us to estimate the **sampling distribution** of a statistic (mean, median, model accuracy, etc.) using only a single observed dataset. It is particularly useful when theoretical assumptions (like normality or large sample size) are not met.

---

## Key Concepts

### Bootstrap Sample

A sample taken **with replacement** from an observed dataset.

### Resampling

The process of taking repeated samples from the data, including both **bootstrap** and **permutation** methods.

---

## Bootstrap Algorithm for the Mean

Let the original dataset `D` have `n = 100` observations.

**Steps:**

1. Draw `n` values with replacement from `D` to form a bootstrap sample.
2. Compute the sample mean.
3. Repeat steps 1 & 2 `R` times (e.g., 1000).
4. Use the resulting `R` bootstrap means to:

   - Estimate the standard error (SE)
   - Create a histogram/boxplot
   - Construct confidence intervals (e.g., 95%)

---

## When to Use Bootstrap

### ✅ Ideal Scenarios

- Small sample sizes
- Unknown population distributions
- Estimating model metrics (e.g., accuracy, AUC)
- Stability analysis
- Confidence interval estimation

### ❌ Limitations

- Dependent data (e.g., time series)
- Very small samples (n < 10)
- Presence of strong outliers
- Heavy computational models

---

## Python Code for Bootstrap (n = 100)

```python
import numpy as np
import matplotlib.pyplot as plt

# Original dataset with n = 100
np.random.seed(42)
data = np.random.exponential(scale=2.0, size=100)  # Non-normal distribution

# Bootstrap parameters
R = 1000
n = len(data)
bootstrap_means = []

# Bootstrap loop
for _ in range(R):
    sample = np.random.choice(data, size=n, replace=True)
    bootstrap_means.append(np.mean(sample))

# Convert to numpy array
bootstrap_means = np.array(bootstrap_means)

# Standard Error
standard_error = np.std(bootstrap_means)
print(f"Bootstrap Standard Error of Mean: {standard_error:.4f}")

# 95% Confidence Interval
ci_lower = np.percentile(bootstrap_means, 2.5)
ci_upper = np.percentile(bootstrap_means, 97.5)
print(f"95% Confidence Interval: ({ci_lower:.4f}, {ci_upper:.4f})")

# Visualization
plt.hist(bootstrap_means, bins=30, color='skyblue', edgecolor='black')
plt.axvline(ci_lower, color='red', linestyle='--', label='2.5th percentile')
plt.axvline(ci_upper, color='red', linestyle='--', label='97.5th percentile')
plt.title('Bootstrap Distribution of the Mean')
plt.xlabel('Mean')
plt.ylabel('Frequency')
plt.legend()
plt.show()
```

---

## Summary Table

| Term             | Explanation                                                  |
| ---------------- | ------------------------------------------------------------ |
| Bootstrap Sample | Sample drawn with replacement from original data             |
| Resampling       | Taking multiple samples (includes bootstrap and permutation) |
| Sampling Dist.   | Distribution of statistic over many bootstrap samples        |
| Standard Error   | Estimated from std deviation of bootstrap samples            |
| Confidence Int.  | Percentile-based bounds from bootstrap distribution          |

---

## Real-Life Applications

- **Model Evaluation**: Estimate variance of AUC or F1-score
- **Hypothesis Testing**: Bootstrap difference of means/medians
- **Model Explainability**: Assess feature importance variability

---

## Extensions

- **Block Bootstrap**: For time series
- **Bootstrap-t**: Improved CIs for small sample sizes
- **BCa Intervals**: Bias-corrected and accelerated intervals

---

> **Bootstrap provides empirical power when theory fails.** It is flexible, assumption-light, and widely used in modern data science workflows.

---
