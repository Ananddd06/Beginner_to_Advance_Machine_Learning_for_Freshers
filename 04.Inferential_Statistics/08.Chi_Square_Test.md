# ğŸ§ª Chi-Square Test: In-Depth Explanation

## ğŸ“Œ What is the Chi-Square Test?

The **Chi-Square Test (Ï‡Â² test)** is a statistical method used to determine whether there's a significant association between **categorical variables** or whether an observed distribution differs from an expected distribution.

It helps answer questions like:

- "Is there a relationship between gender and product preference?"
- "Does the observed frequency of dice rolls match what's expected in a fair dice?"

---

## ğŸ§  Why Do We Use the Chi-Square Test?

- To **test independence** between two categorical variables.
- To **check goodness-of-fit** for a distribution.
- To **detect associations** in survey or experimental data.

It is particularly useful when data is **non-parametric** (not assuming a normal distribution).

---

## âœ… When to Use Chi-Square

| Condition                          | Description                                |
| ---------------------------------- | ------------------------------------------ |
| Data is **categorical**            | e.g. Male/Female, Pass/Fail, Yes/No        |
| Variables are **independent**      | Observations must not influence each other |
| Sample size is **adequate**        | Expected frequency in each cell â‰¥ 5        |
| Uses **frequency** not percentages | Input must be raw counts                   |

---

## ğŸ§ª Types of Chi-Square Tests

### 1. **Chi-Square Test for Independence**

- Used to determine whether **two categorical variables are independent**.
- Example: Is **gender** independent of **voting preference**?

### 2. **Chi-Square Goodness-of-Fit Test**

- Used to check if a **sample distribution fits a theoretical distribution**.
- Example: Do observed dice rolls fit the expected uniform distribution?

---

## ğŸ”¢ Formula for Chi-Square Statistic

For both tests, the test statistic is:

$$
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}
$$

Where:

- \( O_i \) = Observed frequency
- \( E_i \) = Expected frequency

---

## ğŸ“Š Chi-Square Test for Independence: Example

|        | Likes A | Likes B | Total |
| ------ | ------- | ------- | ----- |
| Male   | 20      | 30      | 50    |
| Female | 40      | 10      | 50    |
| Total  | 60      | 40      | 100   |

Expected value for Male & A:

$$
E = \frac{\text{Row Total} \times \text{Column Total}}{\text{Grand Total}} = \frac{50 \times 60}{100} = 30
$$

Compute Ï‡Â²:

$$
\chi^2 = \sum \frac{(O - E)^2}{E}
$$

Then compare with critical value from the Chi-Square table at \( df = (r - 1)(c - 1) \)

---

## ğŸ“ˆ Chi-Square Goodness-of-Fit Example

**Observed Frequencies:** [18, 22, 20, 25, 15]  
**Expected Frequencies:** [20, 20, 20, 20, 20]

Compute:

$$
\chi^2 = \frac{(18 - 20)^2}{20} + \frac{(22 - 20)^2}{20} + \cdots = 3.5
$$

Compare to critical value with \( df = k - 1 = 5 - 1 = 4 \)

---

## ğŸ“ Degrees of Freedom

- **Goodness-of-Fit:** \( df = k - 1 \)
- **Test of Independence:** \( df = (r - 1)(c - 1) \)

---

## ğŸ” p-value Interpretation

- If **p < Î± (e.g., 0.05)** â†’ reject the null hypothesis.
- If **p â‰¥ Î±** â†’ fail to reject the null.

---

## Python Code For Implementing the Math Behind the Chi Square Test

```python
import pandas as pd
import numpy as np

chi2_test_result = []

# This is respect to the US visa kind of the Dataset where it has a lot of categorical features we used this to obtain the p value

for feature in categorical_features:
    # Step 1: Create contingency table
    table = pd.crosstab(df[feature], df['case_status'])

    # Step 2: Get observed frequencies (O)
    observed = table.values

    # Step 3: Compute expected frequencies (E)
    row_totals = observed.sum(axis=1).reshape(-1, 1)
    col_totals = observed.sum(axis=0).reshape(1, -1)
    grand_total = observed.sum()

    expected = (row_totals @ col_totals) / grand_total

    # Step 4: Compute chi-square statistic
    chi2_stat = ((observed - expected) ** 2 / expected).sum()

    # Step 5: Compute degrees of freedom (n- 1)
    dof = (observed.shape[0] - 1) * (observed.shape[1] - 1)

    # Step 6: Compute p-value using chi-square distribution
    from scipy.stats import chi2
    p_value = 1 - chi2.cdf(chi2_stat, dof)

    # Step 7: Decide on hypothesis
    if p_value < 0.05:
        chi2_test_result.append("Reject Null Hypothesis")
    else:
        chi2_test_result.append("Fail to Reject Null Hypothesis")

# Step 8: Create final result DataFrame
result = pd.DataFrame({'Column': categorical_features, 'Hypothesis Result': chi2_test_result})
print(result)

```

## âš ï¸ Assumptions and Limitations

- Expected frequencies should be â‰¥ 5.
- Observations must be independent.
- Only works with **counts**, not continuous data or proportions.
- Sensitive to **sample size** â€” large samples can show significance even for trivial effects.

---

## ğŸ§µ Key Use Cases

- Survey analysis
- Clinical trials (e.g., treatment vs control group)
- Market research (e.g., preference across regions)
- Genetic studies (e.g., Mendelian inheritance)

---

## ğŸ”š Conclusion

The **Chi-Square Test** is a powerful tool for analyzing categorical data. It enables:

- Testing of relationships (independence test)
- Checking model fit (goodness-of-fit test)

It's one of the fundamental tools in **hypothesis testing** when dealing with **non-numeric** outcomes.

---

## ğŸ“š References

- [Wikipedia: Chi-Square Test](https://en.wikipedia.org/wiki/Chi-squared_test)
- "Statistical Methods for the Social Sciences" by Alan Agresti
- SciPy documentation: [`scipy.stats.chi2_contingency`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)
