# 📊 Hypothesis Testing: Z-Test and T-Test from Scratch in Python

In this guide, we implement Z-Test and T-Test **from scratch** to identify if a feature significantly contributes to the target variable. If **we fail to reject the null hypothesis**, we consider that feature as statistically insignificant and **remove it from the dataset**.

---

## 📌 Problem Setup

Let’s simulate a dataset of 50 samples with a numerical feature and a binary target. We'll test if the feature significantly affects the target.

---

## 🧪 Step-by-Step Z-Test & T-Test

```python
import numpy as np
import scipy.stats as stats
import pandas as pd

# Step 1: Simulate data
np.random.seed(42)
n = 50
feature = np.random.normal(loc=50, scale=10, size=n)  # simulated feature
target = np.random.choice([0, 1], size=n)  # binary target

data = pd.DataFrame({
    'feature': feature,
    'target': target
})

# Step 2: Split feature based on target
group1 = data[data['target'] == 0]['feature']
group2 = data[data['target'] == 1]['feature']

n1 = len(group1)
n2 = len(group2)

# Print group stats
print(f"Group 1 size: {n1}, mean: {group1.mean():.2f}, std: {group1.std():.2f}")
print(f"Group 2 size: {n2}, mean: {group2.mean():.2f}, std: {group2.std():.2f}")

# Step 3: Perform Z-Test (assume population std is known ~ 10)
pop_std = 10
z_stat = (group1.mean() - group2.mean()) / np.sqrt((pop_std**2 / n1) + (pop_std**2 / n2))
p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print(f"\n📌 Z-Test")
print(f"Z-Statistic: {z_stat:.4f}")
print(f"P-Value: {p_value_z:.4f}")

# Step 4: Perform T-Test
t_stat, p_value_t = stats.ttest_ind(group1, group2, equal_var=False)  # Welch's T-test
dof = (group1.var()/n1 + group2.var()/n2)**2 / ((group1.var()/n1)**2/(n1-1) + (group2.var()/n2)**2/(n2-1))

print(f"\n📌 T-Test")
print(f"T-Statistic: {t_stat:.4f}")
print(f"P-Value: {p_value_t:.4f}")
print(f"Degrees of Freedom: {dof:.2f}")

# Step 5: Hypothesis Testing
alpha = 0.05

def check_significance(p_value, test_name):
    if p_value < alpha:
        print(f"✅ {test_name}: Reject the Null Hypothesis (Feature is significant)")
    else:
        print(f"❌ {test_name}: Fail to Reject the Null Hypothesis (Feature is NOT significant — remove it)")

check_significance(p_value_z, "Z-Test")
check_significance(p_value_t, "T-Test")

# Step 6: Drop feature if not significant
if p_value_t > alpha:
    data.drop(columns=['feature'], inplace=True)
    print("\n🧹 Feature dropped due to insignificance.")
else:
    print("\n✅ Feature retained.")
```
