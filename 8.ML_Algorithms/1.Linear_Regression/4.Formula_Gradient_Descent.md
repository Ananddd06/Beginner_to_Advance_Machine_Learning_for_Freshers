# Gradient Descent for Linear Regression

The update rule for Gradient Descent is:

$$
\theta_j = \theta_j - \alpha \cdot \frac{\partial J(\theta)}{\partial \theta_j}
$$

where:

- \( \theta_j \) is the parameter (weight or bias) we want to update.
- \( \alpha \) is the learning rate (step size).
- \( J(\theta) \) is the cost function (Mean Squared Error in Linear Regression).
- \( \frac{\partial J(\theta)}{\partial \theta_j} \) is the gradient of the cost function with respect to \( \theta_j \).

---

## Gradient Descent Update for Linear Regression

For **Linear Regression**, the cost function is:

$$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_{\theta}(x_i) - y_i)^2
$$

where:

- \( h\_{\theta}(x) = \theta_0 + \theta_1 x \) (hypothesis function)
- \( m \) is the number of training examples.

The **partial derivatives (gradients)** are:

$$
\frac{\partial J}{\partial \theta_0} = \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x_i) - y_i)
$$

$$
\frac{\partial J}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} (h_{\theta}(x_i) - y_i) x_i
$$

So the **parameter updates** are:

$$
\theta_0 = \theta_0 - \alpha \cdot \frac{1}{m} \sum (h_{\theta}(x) - y)
$$

$$
\theta_1 = \theta_1 - \alpha \cdot \frac{1}{m} \sum (h_{\theta}(x) - y) \cdot x
$$

- PYTHON CODE FOR THAT

```python
import numpy as np
import matplotlib.pyplot as plt

# Generate random data
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)  # y = 4 + 3X + noise

# Initialize parameters
theta_0 = np.random.randn()  # Intercept
theta_1 = np.random.randn()  # Slope

# Hyperparameters
alpha = 0.1  # Learning rate
iterations = 1000
m = len(X)

cost_history = []

# Gradient Descent
for i in range(iterations):
    y_pred = theta_0 + theta_1 * X  # Hypothesis function

    error = y_pred - y  # Error term

    # Compute gradients
    grad_theta_0 = (1/m) * np.sum(error)  # Derivative wrt theta_0
    grad_theta_1 = (1/m) * np.sum(error * X)  # Derivative wrt theta_1

    # Update parameters using gradient descent
    theta_0 -= alpha * grad_theta_0
    theta_1 -= alpha * grad_theta_1

    # Compute cost
    cost = (1/(2*m)) * np.sum(error**2)
    cost_history.append(cost)

# Plot cost function convergence
plt.figure(figsize=(8, 5))
plt.plot(range(iterations), cost_history, 'b-', label="Cost Function (MSE)")
plt.xlabel("Iterations")
plt.ylabel("Cost (MSE)")
plt.title("Convergence of Gradient Descent")
plt.legend()
plt.show()

# Plot best-fit line
plt.figure(figsize=(8, 5))
plt.scatter(X, y, color="blue", label="Data points")
plt.plot(X, theta_0 + theta_1 * X, color="red", linewidth=2, label="Best Fit Line")
plt.xlabel("X")
plt.ylabel("y")
plt.title("Best Fit Line using Gradient Descent")
plt.legend()
plt.show()

# Print final parameters
print(f"Optimal Intercept (theta_0): {theta_0:.4f}")
print(f"Optimal Slope (theta_1): {theta_1:.4f}")

```
