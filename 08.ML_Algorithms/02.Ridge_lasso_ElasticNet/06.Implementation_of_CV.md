# ðŸŽ¯ **Cross-Validation Techniques in Python**

## ðŸ“Œ **1. Leave-One-Out Cross-Validation (LOO-CV)**

ðŸ”¹ **How it Works?**

- Each sample is used once as a test set while the rest are used for training.
- Computationally expensive for large datasets.

```python
from sklearn.model_selection import LeaveOneOut
from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error
import numpy as np

# Generate synthetic dataset
X, y = make_regression(n_samples=10, n_features=1, noise=0.1, random_state=42)

loo = LeaveOneOut()
model = LinearRegression()
mse_scores = []

# Loop over each split
for train_idx, test_idx in loo.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse_scores.append(mean_squared_error(y_test, y_pred))

print(f"Average MSE from LOO-CV: {np.mean(mse_scores)}")

```

## ðŸ“Œ **2. Leave-P-Out Cross-Validation (LPO-CV)**

```python
from sklearn.model_selection import LeavePOut

lpo = LeavePOut(p=2)
model = LinearRegression()
mse_scores = []

for train_idx, test_idx in lpo.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse_scores.append(mean_squared_error(y_test, y_pred))

print(f"Average MSE from LPO-CV: {np.mean(mse_scores)}")

```

## ðŸ“Œ **3. K-Fold CV**

```python
from sklearn.model_selection import KFold, cross_val_score

kf = KFold(n_splits=5, shuffle=True, random_state=42)
model = LinearRegression()

scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')
print(f"Average MSE from K-Fold CV: {-np.mean(scores)}")

```

## ðŸ“Œ **4. Stratified-k-fold**

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

# Generate classification dataset
X_class, y_class = make_classification(n_samples=100, n_features=5, weights=[0.9, 0.1], random_state=42)

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
model = LogisticRegression()

scores = cross_val_score(model, X_class, y_class, cv=skf, scoring='accuracy')
print(f"Average Accuracy from Stratified K-Fold CV: {np.mean(scores)}")

```

## ðŸ“Œ **4. Time-Series-CV**

```python
from sklearn.model_selection import TimeSeriesSplit

# Generate time-series-like data
np.random.seed(42)
X_time = np.arange(100).reshape(-1, 1)
y_time = X_time.ravel() + np.random.normal(scale=5, size=100)

tscv = TimeSeriesSplit(n_splits=5)
model = LinearRegression()
mse_scores = []

for train_idx, test_idx in tscv.split(X_time):
    X_train, X_test = X_time[train_idx], X_time[test_idx]
    y_train, y_test = y_time[train_idx], y_time[test_idx]

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse_scores.append(mean_squared_error(y_test, y_pred))

print(f"Average MSE from Time Series CV: {np.mean(mse_scores)}")

```
